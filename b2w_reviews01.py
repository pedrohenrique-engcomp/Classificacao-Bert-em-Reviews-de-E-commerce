# -*- coding: utf-8 -*-
"""B2W-Reviews01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DmJvIntYWor7WrkfOzdRYWEm1sDDWWLi
"""

!pip install evaluate
!pip install --upgrade transformers
import pandas as pd
import numpy as np
import evaluate
from datasets import Dataset
from sklearn.model_selection import train_test_split
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer
)

# --- 1. Carga e Limpeza dos Dados Reais (Kaggle) ---

print("Carregando dataset B2W...")
# Certifique-se de que o arquivo 'B2W-Reviews01.csv' est√° na mesma pasta
try:
    # O dataset B2W usa ';' como separador, diferente do padr√£o ','
    # CORRE√á√ÉO: Pelo erro, o separador parece ser na verdade a v√≠rgula ','
    df = pd.read_csv('B2W-Reviews01.csv', sep=',', on_bad_lines='skip', low_memory=False)
except FileNotFoundError:
    print("ERRO: Arquivo 'B2W-Reviews01.csv' n√£o encontrado.")
    print("Por favor, baixe o dataset do Kaggle e fa√ßa o upload.")
    # Para o c√≥digo n√£o quebrar se voc√™ rodar sem o arquivo, vou criar um dummy s√≥ para demonstra√ß√£o:
    df = pd.DataFrame({'review_text': ['Teste'], 'overall_rating': [5]})

# --- Diagn√≥stico: Verificar colunas lidas ---
print(f"Colunas lidas: {df.columns.tolist()}")

# Filtrar apenas as colunas que importam
df = df[['review_text', 'overall_rating']]

# Limpeza Cr√≠tica: Remover linhas onde o texto √© nulo/vazio
print(f"Tamanho original: {len(df)}")
df = df.dropna(subset=['review_text'])
df['review_text'] = df['review_text'].astype(str) # Garante que tudo √© string
print(f"Tamanho ap√≥s limpeza de nulos: {len(df)}")

"""##
2
"""

# --- 2. L√≥gica de Neg√≥cio: Transformar Estrelas em Sentimento ---

def converter_nota_para_sentimento(nota):
    if nota <= 2:
        return 0 # Negativo
    elif nota == 3:
        return 1 # Neutro
    else:
        return 2 # Positivo
# Aplica a fun√ß√£o
df['labels'] = df['overall_rating'].apply(converter_nota_para_sentimento)

# OTIMIZA√á√ÉO: Balanceamento e Amostragem
# Datasets reais costumam ter muito mais avalia√ß√µes positivas.
# Para treinar r√°pido e validar o conceito, vamos pegar uma amostra balanceada (ex: 1500 de cada).
# Isso evita que o modelo vicie em dizer que "tudo √© positivo".

df_neg = df[df['labels'] == 0].sample(n=1500, random_state=42)
df_neu = df[df['labels'] == 1].sample(n=1500, random_state=42)
df_pos = df[df['labels'] == 2].sample(n=1500, random_state=42)

df_balanced = pd.concat([df_neg, df_neu, df_pos])
df_balanced = df_balanced.sample(frac=1).reset_index(drop=True) # Embaralhar

print(f"Dataset final balanceado: {len(df_balanced)} exemplos.")

"""##3

"""

# --- 3. Prepara√ß√£o para o Hugging Face ---
# Mapeamento para refer√™ncia futura
id2label = {0: "Negativo", 1: "Neutro", 2: "Positivo"}
label2id = {"Negativo": 0, "Neutro": 1, "Positivo": 2}
# Divis√£o Treino/Teste
train_df, test_df = train_test_split(df_balanced, test_size=0.2, random_state=42)

# Converter para formato Dataset do HF
dataset_train = Dataset.from_pandas(train_df)
dataset_test = Dataset.from_pandas(test_df)

# Tokeniza√ß√£o (Igual ao exemplo anterior, mas agora com dados reais)
model_name = "neuralmind/bert-base-portuguese-cased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def tokenize_function(examples):
    # Truncation √© vital aqui pois algumas reviews podem ser text√µes enormes
    return tokenizer(examples['review_text'], padding="max_length", truncation=True, max_length=128)

tokenized_train = dataset_train.map(tokenize_function, batched=True)
tokenized_test = dataset_test.map(tokenize_function, batched=True)

"""##4

"""

model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=3,
    id2label=id2label,
    label2id=label2id
)

accuracy = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return accuracy.compute(predictions=predictions, references=labels)

# Argumentos otimizados para um "Fine-Tuning" r√°pido e eficiente
training_args = TrainingArguments(
    output_dir="b2w_bert_finetuned",
    eval_strategy="epoch", # Alterado de evaluation_strategy para eval_strategy
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16, # Aumentei um pouco pois diminuimos o max_length para 128
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    report_to="none" # Desabilita logs externos (wandb) para manter simples
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_test,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

# --- 5. Execu√ß√£o ---
print("Iniciando treinamento com dados reais do B2W...")
trainer.train()

"""##5."""

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
from transformers import pipeline
import seaborn as sns
# Avalia√ß√£o final
metrics = trainer.evaluate()
print("\nAcur√°cia no conjunto de teste:", metrics['eval_accuracy'])

# Salvar o modelo final
trainer.save_model("./modelo_b2w_sentimento")
print("Modelo salvo com sucesso. Pronto para o Projeto 2!")

# --- 1. Obter Previs√µes e R√≥tulos Verdadeiros ---

# O trainer.predict() nos d√° as previs√µes (logits) e os r√≥tulos verdadeiros
print("Calculando previs√µes no conjunto de teste...")
predictions_output = trainer.predict(tokenized_test)

# predictions_output.predictions s√£o os logits (valores brutos de sa√≠da)
# Usamos np.argmax para encontrar o √≠ndice da classe com maior probabilidade
y_pred = np.argmax(predictions_output.predictions, axis=1)

# predictions_output.label_ids s√£o os r√≥tulos verdadeiros
y_true = predictions_output.label_ids

# Nossos r√≥tulos (importante manter a ordem: 0, 1, 2)
class_labels = ["Negativo", "Neutro", "Positivo"]

# --- 2. Relat√≥rio de Classifica√ß√£o (Precision, Recall, F1) ---

print("\n--- Relat√≥rio de Classifica√ß√£o Detalhado ---")
# Isso √© mais poderoso que apenas sensibilidade/especificidade para 3 classes
# "Recall" √© o mesmo que "Sensibilidade"
print(classification_report(y_true, y_pred, target_names=class_labels))

# --- 3. Plotar a Matriz de Confus√£o ---

print("Gerando Matriz de Confus√£o...")
cm = confusion_matrix(y_true, y_pred)

# O c√≥digo que voc√™ forneceu, adaptado para nossos r√≥tulos
plt.figure(figsize=(8, 6))
sns.heatmap(cm,
            annot=True,     # Escreve os n√∫meros dentro das c√©lulas
            fmt='d',        # Formato dos n√∫meros (inteiro)
            cmap='Blues',   # Esquema de cores
            xticklabels=class_labels,
            yticklabels=class_labels)

plt.title('Matriz de Confus√£o - Modelo BERT', fontsize=16)
plt.ylabel('Verdadeiro (Real)', fontsize=12)
plt.xlabel('Predito (Modelo)', fontsize=12)
plt.show()

from transformers import pipeline
import pandas as pd
import os

# Excluir explicitamente a vari√°vel de ambiente HF_TOKEN para evitar problemas de autentica√ß√£o
os.environ.pop('HF_TOKEN', None)

# 1. Carregar o pipeline de NER pr√©-treinado para portugu√™s
# O 'aggregation_strategy="simple"' agrupa sub-palavras
# Ex: "Ama" e "##zon" se tornam "Amazon" com a tag ORG
print("Carregando modelo NER (pode levar um momento)...")
# Usando um modelo NER multil√≠ngue gen√©rico que costuma funcionar sem token
nlp_ner = pipeline("ner",
                   model="Davlan/bert-base-multilingual-cased-ner-hrl",
                   aggregation_strategy="simple",
                   token=None) # Garantir que nenhum token seja usado

print("Modelo carregado.")

# 2. Vamos usar alguns dos seus exemplos e adicionar um com marcas
textos_para_teste = [
    "Excelente produto, recomendo. A entrega da Magalu foi r√°pida.",
    "Nao recebi o produto, quero meu dinheiro de volta. Falei com o atendente Jo√£o.",
    "n√£o consigo encontrar maquiagem na black friday que meu bolso consegue pagar... triste & sem dinheiro",
    "Man t√¥ na mesma situa√ß√£o t√¥ com 100 reais na carteira da psn j√° a 2 semanas esperando a Black Friday pra comprar o days gone",
    "Comprei um iPhone 12 na loja da Vivo em S√£o Paulo e estou adorando."
]

print("\n--- Iniciando Extra√ß√£o de Entidades ---")

# 3. Processar cada texto e exibir os resultados
for i, texto in enumerate(textos_para_teste):
    print(f"\n[ Texto {i+1} ]: \"{texto}\"")

    # Executa o pipeline
    entities = nlp_ner(texto)

    if not entities:
        print(" -> Nenhuma entidade reconhecida.")
    else:
        # Imprime as entidades encontradas
        print(" -> Entidades encontradas:")
        for ent in entities:
            print(f"    - Entidade: '{ent['word']}'")
            print(f"      Tipo: {ent['entity_group']}") # entity_group √© o nome da label (ex: ORG, PER)
            print(f"      Confian√ßa: {ent['score']:.2%}")

"""### An√°lise de Sentimento e NER em Reviews de E-commerce (PT-BR)

Este projeto implementa um pipeline completo de Processamento de Linguagem Natural (NLP) focado em reviews de produtos no mercado brasileiro. O sistema utiliza **Fine-Tuning** de um modelo BERT pr√©-treinado para classifica√ß√£o de sentimentos e um pipeline secund√°rio para Extra√ß√£o de Entidades Nomeadas (NER).

###üìã Vis√£o Geral

O projeto est√° dividido em dois m√≥dulos principais:

1. **Classificador de Sentimentos**: Treinamento de um modelo para categorizar coment√°rios em Negativo, Neutro ou Positivo, utilizando o dataset B2W.

2. **Reconhecimento de Entidades (NER)**: Extra√ß√£o de nomes de pessoas, organiza√ß√µes e locais a partir de textos n√£o estruturados.

###üõ†Ô∏è **Tecnologias e Depend√™ncias**

O c√≥digo foi desenvolvido em Python e utiliza o ecossistema Hugging Face.

**Principais Bibliotecas:**

``transformers``: Modelos e pipelines de NLP.

``evaluate & sklearn``: C√°lculo de m√©tricas e matriz de confus√£o.

``datasets``: Manipula√ß√£o eficiente de dados para o Hugging Face.

``pandas & numpy``: Manipula√ß√£o de dados tabulares.

``seaborn & matplotlib``: Visualiza√ß√£o de dados.

Instala√ß√£o:
``
!pip install evaluate
!pip install --upgrade transformers
!pip install datasets scikit-learn pandas seaborn
``

###**üìä Dataset e Pr√©-processamento**

Fonte dos Dados: ``B2W-Reviews01.csv`` (Dataset p√∫blico de reviews do grupo B2W).

1. **Limpeza e Transforma√ß√£o**

* **Tratamento de Separadores**: O arquivo √© lido ajustando separadores para evitar erros de bad lines.

* **Remo√ß√£o de Nulos**: Linhas sem texto de review s√£o descartadas.

* **Convers√£o de Labels**: As notas (estrelas de 1 a 5) s√£o convertidas para sentimentos:

* ‚≠ê 1 e 2 ‚Üí 0 (Negativo)

* ‚≠ê 3 ‚Üí 1 (Neutro)

* ‚≠ê 4 e 5 ‚Üí 2 (Positivo)

2. **Balanceamento de Classes**

Para evitar vi√©s (j√° que reviews positivos s√£o predominantes), aplicou-se uma sub-amostragem (undersampling):

Selecionados aleatoriamente 1.500 exemplos de cada classe (Negativo, Neutro, Positivo).

Total do dataset de treino/teste: 4.500 exemplos.

Divis√£o: 80% Treino / 20% Teste.

###**üß† Modelo de Sentimento (Fine-Tuning)**

Utilizou-se o modelo **BERTimbau** ``(neuralmind/bert-base-portuguese-cased)``, o estado da arte para l√≠ngua portuguesa.

**Configura√ß√µes de Treinamento**

* **√âpocas**: 3

* **Learning Rate**: 2e-5

* **Batch Size**: 16

* **Max Length**: 128 tokens (truncamento para otimiza√ß√£o).

* **Otimizador**: AdamW com Weight Decay.

**Resultados Obtidos**

Ap√≥s o treinamento, o modelo foi avaliado no conjunto de teste (900 amostras):

| M√©trica | Valor |
| :--- | :--- |
| **Acur√°cia Global** | **76.89%** |

**Performance por Classe**:

Negativo: Alta precis√£o (87%) e Recall (83%). O modelo distingue bem reclama√ß√µes.

Positivo: Bom equil√≠brio (81% Precision / 81% Recall).

Neutro: √â a classe mais dif√≠cil (63% Precision), frequentemente confundida com positivos ou negativos leves.

O modelo final foi salvo no diret√≥rio ``./modelo_b2w_sentimento.``

###**üîç M√≥dulo de NER (Named Entity Recognition)**

Al√©m da classifica√ß√£o, implementou-se um pipeline para extra√ß√£o de entidades usando o modelo ``Davlan/bert-base-multilingual-cased-ner-hrl.``

**Objetivo**: Identificar:

* ``PER``: Pessoas (ex: nomes de atendentes).

* ``ORG``: Organiza√ß√µes (ex: Lojas, Marcas).

* ``LOC``: Locais (ex: Cidades, Estados).

**Exemplo de Sa√≠da**:

Texto: "Falei com o atendente Jo√£o."

* Entidade: Jo√£o (PER) | Confian√ßa: 99.91%

Texto: "Comprei um iPhone 12 na loja da Vivo em S√£o Paulo."

* Entidade: Vivo (ORG)

* Entidade: S√£o Paulo (LOC)

###üöÄ **Como Executar**

1. Certifique-se de ter o arquivo B2W-Reviews01.csv no diret√≥rio raiz.

2. Execute o script de Carga e Treinamento para gerar o modelo de sentimento.

3. O script gerar√° automaticamente:

* M√©tricas no console.

* Uma Matriz de Confus√£o visual (plotada com Seaborn).

4. Execute o bloco de Infer√™ncia NER para testar a extra√ß√£o de entidades em frases arbitr√°rias.

###‚ö†Ô∏è **Notas Importantes**

* **Autentica√ß√£o HF**: O script remove explicitamente o token do Hugging Face (os.environ.pop('HF_TOKEN')) para evitar conflitos em ambientes p√∫blicos/compartilhados.

* **Tratamento de Erros**: H√° um bloco try/except na leitura do CSV que cria um DataFrame dummy caso o arquivo n√£o seja encontrado, permitindo testar o c√≥digo sem o dataset completo.

**Cr√©ditos dos Modelos**:

* NeuralMind (BERTimbau)

* Davlan (Multilingual NER)
"""