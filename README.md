# Classificacao-Bert-em-Reviews-de-E-commerce
projeto implementa um pipeline completo de Processamento de Linguagem Natural (NLP) focado em reviews de produtos no mercado brasileiro. O sistema utiliza **Fine-Tuning** de um modelo BERT pr√©-treinado para classifica√ß√£o de sentimentos e um pipeline secund√°rio para Extra√ß√£o de Entidades Nomeadas (NER).

üìã Vis√£o Geral

O projeto est√° dividido em dois m√≥dulos principais:

1. **Classificador de Sentimentos**: Treinamento de um modelo para categorizar coment√°rios em Negativo, Neutro ou Positivo, utilizando o dataset B2W.

2. **Reconhecimento de Entidades (NER)**: Extra√ß√£o de nomes de pessoas, organiza√ß√µes e locais a partir de textos n√£o estruturados.

üõ†Ô∏è **Tecnologias e Depend√™ncias**

O c√≥digo foi desenvolvido em Python e utiliza o ecossistema Hugging Face.

**Principais Bibliotecas:**

``transformers``: Modelos e pipelines de NLP.

``evaluate & sklearn``: C√°lculo de m√©tricas e matriz de confus√£o.

``datasets``: Manipula√ß√£o eficiente de dados para o Hugging Face.

``pandas & numpy``: Manipula√ß√£o de dados tabulares.

``seaborn & matplotlib``: Visualiza√ß√£o de dados.

Instala√ß√£o:
``
!pip install evaluate
!pip install --upgrade transformers
!pip install datasets scikit-learn pandas seaborn
``

**üìä Dataset e Pr√©-processamento**

Fonte dos Dados: ``B2W-Reviews01.csv`` (Dataset p√∫blico de reviews do grupo B2W).

1. **Limpeza e Transforma√ß√£o**

* **Tratamento de Separadores**: O arquivo √© lido ajustando separadores para evitar erros de bad lines.

* **Remo√ß√£o de Nulos**: Linhas sem texto de review s√£o descartadas.

* **Convers√£o de Labels**: As notas (estrelas de 1 a 5) s√£o convertidas para sentimentos:

* ‚≠ê 1 e 2 ‚Üí 0 (Negativo)

* ‚≠ê 3 ‚Üí 1 (Neutro)

* ‚≠ê 4 e 5 ‚Üí 2 (Positivo)

2. **Balanceamento de Classes**

Para evitar vi√©s (j√° que reviews positivos s√£o predominantes), aplicou-se uma sub-amostragem (undersampling):

Selecionados aleatoriamente 1.500 exemplos de cada classe (Negativo, Neutro, Positivo).

Total do dataset de treino/teste: 4.500 exemplos.

Divis√£o: 80% Treino / 20% Teste.

**üß† Modelo de Sentimento (Fine-Tuning)**

Utilizou-se o modelo **BERTimbau** ``(neuralmind/bert-base-portuguese-cased)``, o estado da arte para l√≠ngua portuguesa.

**Configura√ß√µes de Treinamento**

* **√âpocas**: 3

* **Learning Rate**: 2e-5

* **Batch Size**: 16

* **Max Length**: 128 tokens (truncamento para otimiza√ß√£o).

* **Otimizador**: AdamW com Weight Decay.

**Resultados Obtidos**

Ap√≥s o treinamento, o modelo foi avaliado no conjunto de teste (900 amostras):

| M√©trica | Valor |
| :--- | :--- |
| **Acur√°cia Global** | **76.89%** |

**Performance por Classe**:

Negativo: Alta precis√£o (87%) e Recall (83%). O modelo distingue bem reclama√ß√µes.

Positivo: Bom equil√≠brio (81% Precision / 81% Recall).

Neutro: √â a classe mais dif√≠cil (63% Precision), frequentemente confundida com positivos ou negativos leves.

O modelo final foi salvo no diret√≥rio ``./modelo_b2w_sentimento.``

**üîç M√≥dulo de NER (Named Entity Recognition)**

Al√©m da classifica√ß√£o, implementou-se um pipeline para extra√ß√£o de entidades usando o modelo ``Davlan/bert-base-multilingual-cased-ner-hrl.``

**Objetivo**: Identificar:

* ``PER``: Pessoas (ex: nomes de atendentes).

* ``ORG``: Organiza√ß√µes (ex: Lojas, Marcas).

* ``LOC``: Locais (ex: Cidades, Estados).

**Exemplo de Sa√≠da**:

Texto: "Falei com o atendente Jo√£o."

* Entidade: Jo√£o (PER) | Confian√ßa: 99.91%

Texto: "Comprei um iPhone 12 na loja da Vivo em S√£o Paulo."

* Entidade: Vivo (ORG)

* Entidade: S√£o Paulo (LOC)

üöÄ **Como Executar**

1. Certifique-se de ter o arquivo B2W-Reviews01.csv no diret√≥rio raiz.

2. Execute o script de Carga e Treinamento para gerar o modelo de sentimento.

3. O script gerar√° automaticamente:

* M√©tricas no console.

* Uma Matriz de Confus√£o visual (plotada com Seaborn).

4. Execute o bloco de Infer√™ncia NER para testar a extra√ß√£o de entidades em frases arbitr√°rias.

‚ö†Ô∏è **Notas Importantes**

* **Autentica√ß√£o HF**: O script remove explicitamente o token do Hugging Face (os.environ.pop('HF_TOKEN')) para evitar conflitos em ambientes p√∫blicos/compartilhados.

* **Tratamento de Erros**: H√° um bloco try/except na leitura do CSV que cria um DataFrame dummy caso o arquivo n√£o seja encontrado, permitindo testar o c√≥digo sem o dataset completo.

**Cr√©ditos dos Modelos**:

* NeuralMind (BERTimbau)

* Davlan (Multilingual NER)
